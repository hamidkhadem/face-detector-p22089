{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamidkhadem/face-detector-p22089/blob/main/cascade_IUO_metric.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfFCMQOAnfBN"
      },
      "source": [
        "## mount google drive and download data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAP6xl5Onm6I",
        "outputId": "4408d5f2-ccbf-4437-d11b-8d02b64a3cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rj1iHebjrrfu"
      },
      "outputs": [],
      "source": [
        "# Download wiki dataset from this link:https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/\n",
        "!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki.tar.gz -P \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "\n",
        "# extract the zip file - wiki.tar.gz\n",
        "!tar -xvf \"/content/drive/MyDrive/Colab Notebooks/wiki.tar.gz\" -C \"/content/drive/MyDrive/Colab Notebooks/\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_exqHls-gNe5"
      },
      "source": [
        "## Reading dataset's mat file:\n",
        "We are using pymatreader module to read mat file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKXxImrojAqC",
        "outputId": "db19426d-127c-4441-a5cb-7102def7bde4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymatreader\n",
            "  Downloading pymatreader-0.0.30-py3-none-any.whl (9.0 kB)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (from pymatreader) (3.8.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from pymatreader) (0.18.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pymatreader) (1.22.4)\n",
            "Requirement already satisfied: scipy!=1.7.0 in /usr/local/lib/python3.9/dist-packages (from pymatreader) (1.10.1)\n",
            "Installing collected packages: xmltodict, pymatreader\n",
            "Successfully installed pymatreader-0.0.30 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "# install pymatreader package\n",
        "!pip install pymatreader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHLpgBiinhlt"
      },
      "source": [
        "**Finding** face box of in image by reading wiki.mat file and pymatreader library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azz4Xgg0in6T"
      },
      "outputs": [],
      "source": [
        "# using pymatreader lib to read mat file\n",
        "from pymatreader import read_mat\n",
        "\n",
        "# path of mat file\n",
        "path_mat_file = \"/content/drive/MyDrive/Colab Notebooks/wiki/wiki.mat\"\n",
        "# load wiki.mat on a variable\n",
        "mat = read_mat(path_mat_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYOOz33xryEh",
        "outputId": "fa36bfee-d1d3-4701-8a7c-c113309f7374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'wiki'])\n",
            "b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sat Jan 16 16:25:20 2016'\n",
            "1.0\n",
            "[]\n",
            "dict_keys(['dob', 'photo_taken', 'full_path', 'gender', 'name', 'face_location', 'face_score', 'second_face_score'])\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "# print info in mat dictionary\n",
        "print(mat.keys())\n",
        "print(mat['__header__'])\n",
        "print(mat['__version__'])\n",
        "print(mat['__globals__'])\n",
        "print(mat['wiki'].keys())\n",
        "print(mat['wiki']['gender'][133])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "craEcFNZLXV3",
        "outputId": "2698dac2-c1e5-47ab-a3bd-455b01ad54ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of mat['wiki']['full_path'] is <class 'list'>\n",
            "lenth of mat['wiki']['full_path'] list is : 62328\n",
            "[ 79.35580189  26.65993396 197.60950472 144.91363679]\n"
          ]
        }
      ],
      "source": [
        "print(f\"type of mat['wiki']['full_path'] is {type(mat['wiki']['full_path'])}\")\n",
        "# print total number of images in wiki dataset\n",
        "print(f\"lenth of mat['wiki']['full_path'] list is : {len(mat['wiki']['full_path'])}\")\n",
        "# print location of one image in wiki dataset\n",
        "print(mat['wiki']['face_location'][6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXToLJAMmWnJ"
      },
      "source": [
        "## Intersection over Union (IOU) accuracy score:\n",
        "defined a function that calculate of IOU from to boxes, one from wiki mat file another from haar cascade detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haVAD6fKmVph"
      },
      "outputs": [],
      "source": [
        "# Example a box input is: { 'width': 156, 'top': 61, 'height': 142, 'left': 363 }\n",
        "def intersection_over_union(box_a, box_b):\n",
        "    # Determine the coordinates of each of the two boxes\n",
        "    xA = max(box_a['left'], box_b['left'])\n",
        "    yA = max(box_a['top'], box_b['top'])\n",
        "    xB = min(box_a['left']+box_a['width'], box_b['left']+box_b['width'])\n",
        "    yB = min(box_a['top']+box_a['height'], box_b['top']+box_b['height'])\n",
        "      \n",
        "    # Calculate the area of the intersection area\n",
        "    area_of_intersection = (xB - xA + 1) * (yB - yA + 1)\n",
        "  \n",
        "    # Calculate the area of both rectangles\n",
        "    box_a_area = (box_a['width'] + 1) * (box_a['height'] + 1)\n",
        "    box_b_area = (box_b['width'] + 1) * (box_b['height'] + 1)\n",
        "\n",
        "    # Calculate the area of intersection divided by the area of union\n",
        "    # Area of union = sum both areas less the area of intersection\n",
        "    iou = area_of_intersection / float(box_a_area + box_b_area - area_of_intersection)\n",
        "    \n",
        "    # Return the score\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1eUPPxkFxLC"
      },
      "source": [
        "## haar cascade face detection\n",
        "First defining the face detection function which get a cascade, number of image in wiki dataset and mat file of wiki dataset. at the end return the dictionary of face box to use for calculate the IOU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUyPPpy0j4cb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "# Face detection Function return dic of face location\n",
        "# Example a = { 'width': 156, 'top': 61, 'height': 142, 'left': 363 }\n",
        "def detect_faces(cascade, num_of_img, mat):\n",
        "\n",
        "  # cause of there are several images in wiki data set that not have a face or other exception\n",
        "  # we use try to skip this error in wiki dataset\n",
        "  try:\n",
        "\n",
        "    # general path to dataset\n",
        "    path_image = '/content/drive/MyDrive/Colab Notebooks/wiki/'\n",
        "    # read image from dataset\n",
        "    img = cv2.imread(path_image + mat['wiki']['full_path'][i])\n",
        "    # create a copy of the image to prevent any changes to the original one.\n",
        "    image_copy = img.copy()\n",
        "\n",
        "    #convert the test image to gray scale as opencv face detector expects gray images\n",
        "    gray_image = cv2.cvtColor(image_copy, cv2.COLOR_BGR2GRAY)\n",
        "    # Applying the haar classifier to detect faces\n",
        "    faces_rect = cascade.detectMultiScale(gray_image)\n",
        "    \n",
        "    # get value of first face detection\n",
        "    x, y, w, h = faces_rect[0]\n",
        "    # Example box = { 'width': 156, 'top': 61, 'height': 142, 'left': 363 }\n",
        "    box = { 'width': w, 'top': y, 'height': h, 'left': x }\n",
        "    return box\n",
        "  # if found exception return None value\n",
        "  except:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7zGui6IQlye"
      },
      "source": [
        "## Change the format of mat face loaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrFrDNgoN8qz"
      },
      "outputs": [],
      "source": [
        "# defined a function that return dictionary of mat face location with desired format:\n",
        "# Example a = { 'width': 156, 'top': 61, 'height': 142, 'left': 363 }\n",
        "def mat_face_box(num_of_img, mat):\n",
        "    # get location of face from mat file\n",
        "    box = mat['wiki']['face_location'][num_of_img]\n",
        "    # change the format of box to example dictionary\n",
        "    box_dic = {'width': int(box[2]), 'top': int(box[1]), 'height': int(box[3]), 'left': int(box[0])}\n",
        "\n",
        "    return box_dic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MaLk8t4K8b5"
      },
      "source": [
        "## Calculate of avrage of all IOU images in wiki dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgKCBVGHm1l3"
      },
      "source": [
        "I use this command to create a haar cascade frontal face ditection object to find location of face in image.\n",
        "```\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "```\n",
        "after that we run a loop to calculate IOU for every valid image in dataset and sum all to calculate average IOU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpKERz-FL9Os",
        "outputId": "59bd3252-5916-4021-81c4-642987028c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average of IOU overall all images in wiki dataset is:  0.2175108199699261\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "# load haar cascade face detection\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades \n",
        "                                     + 'haarcascade_frontalface_default.xml')\n",
        "# find the total number of image in wiki dataset - 62328\n",
        "num_total_img = len(mat['wiki']['full_path'])\n",
        "\n",
        "# defined value that save sum all iou of images\n",
        "total_iou = 0\n",
        "# cause skipping some of image we have to count image to calculate average\n",
        "count_img_with_face = 0\n",
        "# run a loop in desired range to calculate sum of All IOU images in range\n",
        "# i is number of images in wiki dataset\n",
        "for i in range(1000):\n",
        "    # get the box from cascade detection\n",
        "    box_cascade = detect_faces(face_cascade, i, mat)\n",
        "    # check if there is no face in image skip it\n",
        "    if box_cascade == None:\n",
        "      continue\n",
        "    else:\n",
        "      # add one to valid image counter\n",
        "      count_img_with_face += 1\n",
        "      # reformat face location in mat file for IOU function\n",
        "      box_mat = mat_face_box(i, mat)\n",
        "      # calculate IOU for iamge and add to sum of all IOU variable\n",
        "      total_iou += intersection_over_union(box_cascade, box_mat)\n",
        "\n",
        "# calculate the avrage of Overall IOU in wiki dataset\n",
        "avg_iou = total_iou / count_img_with_face\n",
        "print(f\"Average of IOU overall all images in wiki dataset is:  {avg_iou}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yfFCMQOAnfBN",
        "_exqHls-gNe5",
        "WXToLJAMmWnJ",
        "J1eUPPxkFxLC",
        "r7zGui6IQlye"
      ],
      "authorship_tag": "ABX9TyPR5kzU5jzZDNNTlrr54W92",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}